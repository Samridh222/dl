{"cells":[{"cell_type":"markdown","source":["# python program to train neural network using Stochastic Gradient Descent."],"metadata":{"id":"wUiLBZsxVTBp"},"id":"wUiLBZsxVTBp"},{"cell_type":"code","source":["import numpy as np"],"metadata":{"id":"eyMViBzGVudr"},"id":"eyMViBzGVudr","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"02354858","metadata":{"id":"02354858"},"outputs":[],"source":["def ssr_gradient(x, y, b):\n","    res = b[0] + b[1] * x - y\n","    return res.mean(), (res * x).mean()  # .mean() is a method of np.ndarray\n","\n","#ssr_gradient() takes the arrays x and y, which contain the observation inputs and outputs, and the array b that holds the current values of the decision variables ğ‘â‚€ and ğ‘â‚.\n","#This function first calculates the array of the residuals for each observation (res) and then returns the pair of values of âˆ‚ğ¶/âˆ‚ğ‘â‚€ and âˆ‚ğ¶/âˆ‚ğ‘â‚."]},{"cell_type":"code","execution_count":null,"id":"3454db23","metadata":{"id":"3454db23"},"outputs":[],"source":["x = np.array([5, 15, 25, 35, 45, 55])\n","y = np.array([5, 20, 14, 32, 22, 38])"]},{"cell_type":"code","execution_count":null,"id":"98fa124a","metadata":{"id":"98fa124a"},"outputs":[],"source":["\n","def sgd(gradient, x, y, start, learn_rate=0.1, batch_size=1, n_iter=50,tolerance=1e-06, dtype=\"float64\", random_state=None):\n","    # Checking if the gradient is callable\n","    if not callable(gradient):\n","        raise TypeError(\"'gradient' must be callable\")\n","\n","    # Setting up the data type for NumPy arrays\n","    dtype_ = np.dtype(dtype)\n","\n","    # Converting x and y to NumPy arrays\n","    x, y = np.array(x, dtype=dtype_), np.array(y, dtype=dtype_)\n","    n_obs = x.shape[0]\n","    if n_obs != y.shape[0]:\n","        raise ValueError(\"'x' and 'y' lengths do not match\")\n","    xy = np.c_[x.reshape(n_obs, -1), y.reshape(n_obs, 1)]\n","\n","    # Initializing the random number generator\n","    seed = None if random_state is None else int(random_state)\n","    rng = np.random.default_rng(seed=seed)\n","\n","    # Initializing the values of the variables\n","    vector = np.array(start, dtype=dtype_)\n","\n","    # Setting up and checking the learning rate\n","    learn_rate = np.array(learn_rate, dtype=dtype_)\n","    if np.any(learn_rate <= 0):\n","        raise ValueError(\"'learn_rate' must be greater than zero\")\n","\n","    # Setting up and checking the size of minibatches\n","    batch_size = int(batch_size)\n","    if not 0 < batch_size <= n_obs:\n","        raise ValueError(\n","            \"'batch_size' must be greater than zero and less than \"\n","            \"or equal to the number of observations\"\n","        )\n","\n","    # Setting up and checking the maximal number of iterations\n","    n_iter = int(n_iter)\n","    if n_iter <= 0:\n","        raise ValueError(\"'n_iter' must be greater than zero\")\n","\n","    # Setting up and checking the tolerance\n","    tolerance = np.array(tolerance, dtype=dtype_)\n","    if np.any(tolerance <= 0):\n","        raise ValueError(\"'tolerance' must be greater than zero\")\n","\n","    # Performing the gradient descent loop\n","    for _ in range(n_iter):\n","        # Shuffle x and y\n","        rng.shuffle(xy)\n","\n","        # Performing minibatch moves\n","        for start in range(0, n_obs, batch_size):\n","            stop = start + batch_size\n","            x_batch, y_batch = xy[start:stop, :-1], xy[start:stop, -1:]\n","\n","            # Recalculating the difference\n","            grad = np.array(gradient(x_batch, y_batch, vector), dtype_)\n","            diff = -learn_rate * grad\n","\n","            # Checking if the absolute difference is small enough\n","            if np.all(np.abs(diff) <= tolerance):\n","                break\n","\n","            # Updating the values of the variables\n","            vector += diff\n","\n","    return vector if vector.shape else vector.item()"]},{"cell_type":"code","execution_count":null,"id":"c461763d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c461763d","executionInfo":{"status":"ok","timestamp":1696450692095,"user_tz":-330,"elapsed":8069,"user":{"displayName":"Lakshit Bisht","userId":"15899071240763658350"}},"outputId":"84662269-a859-4f77-cb71-65fcdbe03804"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([5.63093736, 0.53982921])"]},"metadata":{},"execution_count":6}],"source":["sgd(ssr_gradient, x, y, start=[0.5, 0.5], learn_rate=0.0008,batch_size=3, n_iter=100_000, random_state=0)"]},{"cell_type":"code","execution_count":null,"id":"4d748118","metadata":{"id":"4d748118"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}